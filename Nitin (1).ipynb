{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8cac98-b058-43cb-bd1a-94a360f95ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2866cf4f-fcdc-4ac1-8fd0-8c3f102697ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes specified columns ('row_id', 'time_id', 'date_id') from the DataFrame.\n",
    "def remove_unneeded_columns(data_frame):\n",
    "    relevant_columns = [column for column in data_frame.columns if column not in ['row_id', 'time_id', 'date_id']]\n",
    "    cleaned_data = data_frame[relevant_columns]\n",
    "    return cleaned_data\n",
    "\n",
    "#Calculates lower and upper bounds for outliers using the 1st and 99th percentiles of the specified column.\n",
    "def calculate_outlier_limits(data_frame, col):\n",
    "    first_quantile = data_frame[col].quantile(0.01)\n",
    "    third_quantile = data_frame[col].quantile(0.99)\n",
    "    inter_quantile_range = third_quantile - first_quantile\n",
    "    lower_bound = first_quantile - 1.5 * inter_quantile_range\n",
    "    upper_bound = third_quantile + 1.5 * inter_quantile_range\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "#Modifies the values in the specified column of the DataFrame to be within the previously calculated outlier limits.\n",
    "def adjust_outliers(data_frame, col_name):\n",
    "    lower, upper = calculate_outlier_limits(data_frame, col_name)\n",
    "    data_frame.loc[data_frame[col_name] > upper, col_name] = upper\n",
    "    data_frame.loc[data_frame[col_name] < lower, col_name] = lower\n",
    "\n",
    "#Performs several preprocessing steps on the DataFrame and One-hot encodes the 'imbalance_buy_sell_flag' column and Creates a new column 'ratio_imbalance' by dividing 'imbalance_size' by 'matched_size'.\n",
    "def data_preprocessing(data_frame):\n",
    "    data_frame = pd.get_dummies(data_frame, columns=['imbalance_buy_sell_flag'], prefix='flag', drop_first=True)\n",
    "    data_frame['ratio_imbalance'] = data_frame['imbalance_size'] / data_frame['matched_size']\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888f50b-7d7e-486e-a26d-cc0454199776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineered_features(df):\n",
    "    \n",
    "\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "\n",
    "\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "\n",
    "\n",
    "    df[\"bid_ask_size_ratio\"] = df[\"bid_size\"] / df[\"ask_size\"]\n",
    "    df[\"imbalance_bid_size_ratio\"] = df[\"imbalance_size\"] / df[\"bid_size\"]\n",
    "    df[\"imbalance_ask_size_ratio\"] = df[\"imbalance_size\"] / df[\"ask_size\"]\n",
    "    df[\"matched_size_ratio\"] = df[\"matched_size\"] / (df[\"bid_size\"] + df[\"ask_size\"])\n",
    "    df[\"ref_wap_difference\"] = df[\"reference_price\"] - df[\"wap\"]\n",
    "    df[\"bid_ask_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"near_far_price_difference\"] = df[\"far_price\"] - df[\"near_price\"]\n",
    "\n",
    "\n",
    "    df[\"wap_rate_of_change\"] = df.groupby('stock_id')[\"wap\"].pct_change()\n",
    "    df[\"wap_momentum\"] = df.groupby('stock_id')[\"wap\"].diff()\n",
    "\n",
    "    df[\"auction_start\"] = (df[\"seconds_in_bucket\"] == 0).astype(int)\n",
    "    df[\"auction_end\"] = (df[\"seconds_in_bucket\"] == 550).astype(int)\n",
    "    df[\"time_since_last_change\"] = df.groupby('stock_id')['imbalance_buy_sell_flag'].diff(periods=1).ne(0).cumsum()\n",
    "    df[\"time_until_auction_close\"] = 600 - df[\"seconds_in_bucket\"]\n",
    "\n",
    "\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "\n",
    "\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "\n",
    "\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    df['wap_askprice_diff'] = df['ask_price'] - df['wap']\n",
    "    df['wap_bidprice_diff'] = df['wap'] - df['bid_price']\n",
    "    df['wap_askprice_diff_urg'] = df['wap_askprice_diff'] * df['liquidity_imbalance']\n",
    "    df['wap_bidprice_diff_urg'] = df['wap_bidprice_diff'] * df['liquidity_imbalance']\n",
    "    df['bid_size_ask_size_diff'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imbalance_size_matched_size_diff'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "\n",
    "\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  \n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  \n",
    "\n",
    "\n",
    "    global_stock_id_feats = {\n",
    "        \"median_size\": df.groupby(\"stock_id\")[\"bid_size\"].median() + df.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": df.groupby(\"stock_id\")[\"bid_size\"].std() + df.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": df.groupby(\"stock_id\")[\"bid_size\"].max() - df.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": df.groupby(\"stock_id\")[\"bid_price\"].median() + df.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": df.groupby(\"stock_id\")[\"bid_price\"].std() + df.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": df.groupby(\"stock_id\")[\"bid_price\"].max() - df.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9090d2b-b69b-498c-a789-ad13654faf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/input/optiver-trading-at-the-close/train.csv\")\n",
    "test = pd.read_csv(\"/input/optiver-trading-at-the-close/example_test_files/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542f14a-6a6a-4b11-abd0-47528e25d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c9ac7-fccb-4cf6-bd4c-29a43320e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ef49c-88cc-474b-8b68-fb891a817795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a83d2-6336-4d3d-b980-b3db81f0d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffe832-9dc4-40ca-bb45-d51e224d25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919152c2-7002-41bf-8ca1-b6f4ec4c60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ask_p_na = df[df['ask_price'].isna()]\n",
    "print(ask_p_na.stock_id.unique())\n",
    "print(ask_p_na.date_id.unique())\n",
    "print(ask_p_na.seconds_in_bucket.unique())\n",
    "for date in ask_p_na.date_id.unique():\n",
    "    x = df[df.date_id == date]\n",
    "    print(date, x[x.ask_price.isna()]['stock_id'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5470c-f5f8-4d65-8157-376610fe3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna(subset=[\"ask_price\"], axis=0)\n",
    "df.loc[df['seconds_in_bucket'] <= 300, \"near_price\"] = 0\n",
    "df.loc[df['seconds_in_bucket'] <= 300, \"far_price\"] = 0\n",
    "df['far_price'] = df['far_price'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a3ed9-f5bd-4b07-8c0f-1d2b56adb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.isnull().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174493db-edad-43a0-8108-6fb87ede7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = engineered_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab522f78-78a2-4454-bc84-d1d00066403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657f808-6e9d-4323-a78c-da8e152a7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop([\"target\", \"row_id\"], axis=1)\n",
    "y = df[[\"target\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de2374-a426-4455-b1a8-0caf76ed8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lgb_model = lgbm.LGBMRegressor()\n",
    "lgb_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e58eb-0fb5-488b-b196-89ef6f76e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_importance(model, features, num=len(X)):\n",
    "    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",ascending=False)[0:num])\n",
    "    plt.title('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a23d04-a475-4ba4-b486-4fb2087ac71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(lgb_model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3c854-3b63-4974-8693-3ca13580488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\"learning_rate\": [0.01 , 0.1],\n",
    "               \"n_estimators\": [100, 300, 500, 1000],\n",
    "               \"colsample_bytree\": [0.5, 0.7, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c090a67-5c6d-4952-a7be-daa04826544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best_grid = GridSearchCV(lgb_model, lgb_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858206bb-8ac7-44d2-b1b2-3a4c8873a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_final = lgb_model.set_params(**lgbm_best_grid.best_params_, random_state=17).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164fa51-e717-47d5-bf92-d43faf87c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "ctr = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    test = engineered_features(test)\n",
    "    test_df = test.drop([\"row_id\"], axis=1)\n",
    "    sample_prediction['target'] = lgb_model.predict(test_df)\n",
    "    env.predict(sample_prediction)\n",
    "    \n",
    "    ctr += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
